{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from random import seed\n",
    "from mylib.utils import fix_seed\n",
    "from mylib.data.data_loader import load_ucidata\n",
    "import collections\n",
    "import numpy as np\n",
    "from run_dnl import run_dnl\n",
    "import tools\n",
    "import pandas as pd\n",
    "from kmeans import run_kmeans\n",
    "import os\n",
    "import argparse\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "# adjust the load data function to load training data only\n",
    "from mylib.data.data_loader.load_ucidata import load_ucidata2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cal_acc import *\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.decomposition import PCA\n",
    "import SPICE\n",
    "from mylib.data.dataset.util import noisify_multiclass_symmetric\n",
    "\n",
    "from mylib.data.data_loader.subset import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: cd..: command not found\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hungarian_match(flat_preds, flat_targets):\n",
    "    # Based on implementation from IIC\n",
    "    num_samples = flat_targets.shape[0]\n",
    "    v, counts = np.unique(flat_preds, return_counts=True)\n",
    "\n",
    "    num_k = len(v)\n",
    "    num_correct = np.zeros((num_k, num_k))\n",
    "\n",
    "    for c1 in range(num_k):\n",
    "        for c2 in range(num_k):\n",
    "            # elementwise, so each sample contributes once\n",
    "            votes = int(((flat_preds == c1) * (flat_targets == c2)).sum())\n",
    "            num_correct[c1, c2] = votes\n",
    "\n",
    "    row, col = linear_sum_assignment(num_samples - num_correct)\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def get_prime_Y(noisy_classes, pred_classes, mappings):\n",
    "    prime_Y = np.zeros(len(noisy_classes))\n",
    "    for i in range(len(pred_classes)):\n",
    "        prime_Y[i] = mappings[pred_classes[i]]\n",
    "\n",
    "    return prime_Y\n",
    "\n",
    "\n",
    "def count_m(noisy_Y, prime_Y):\n",
    "    values, counts = np.unique(prime_Y, return_counts=True)\n",
    "    # print(values)\n",
    "    length = len(values)\n",
    "    m = np.zeros((length, length))\n",
    "    # print(counts)\n",
    "\n",
    "    for i in range(noisy_Y.shape[0]):\n",
    "        m[int(prime_Y[i])][int(noisy_Y[i])] += 1\n",
    "\n",
    "    sum_matrix = np.tile(counts, (len(values), 1)).transpose()\n",
    "    # print(sum_matrix)\n",
    "    # print(m/sum_matrix)\n",
    "    return m/sum_matrix\n",
    "\n",
    "# define K-means clustering algorithm\n",
    "\n",
    "\n",
    "def run_kmeans2(dataset):\n",
    "\n",
    "    X = dataset.data\n",
    "    clean_Y = dataset.clean_targets\n",
    "    tilde_Y = dataset.targets\n",
    "    values, counts = np.unique(clean_Y, return_counts=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=len(values))\n",
    "    kmeans.fit(X, tilde_Y)\n",
    "    identified_clusters = kmeans.fit_predict(X)\n",
    "\n",
    "    # note that to better match the cluster Id to tilde_Y,\n",
    "    # we could use hat_clean Y which obtained by current noise-robust method, but for the simple dataset , it may not necessary\n",
    "\n",
    "    idx2 = _hungarian_match(identified_clusters, tilde_Y)\n",
    "    prime_Y = get_prime_Y(tilde_Y, identified_clusters, idx2[1])\n",
    "    # yz: directly return prime_Y without using count_m\n",
    "    return prime_Y\n",
    "\n",
    "\n",
    "\n",
    "# --- parsing and configuration --- #\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"PyTorch implementation of VAE\")\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                    help='batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--z_dim', type=int, default=25,\n",
    "                    help='dimension of hidden variable Z (default: 10)')\n",
    "parser.add_argument('--num_hidden_layers', type=int, default=2,\n",
    "                    help='num hidden_layers (default: 0)')\n",
    "parser.add_argument('--flip_rate_fixed', type=float,\n",
    "                    help='fixed flip rates.', default=0.4)\n",
    "parser.add_argument('--train_frac', default=1.0, type=float,\n",
    "                    help='training sample size fraction')\n",
    "parser.add_argument('--noise_type', type=str, default='sym')\n",
    "parser.add_argument('--trainval_split',  default=0.8, type=float,\n",
    "                    help='training set ratio')\n",
    "parser.add_argument('--seed', default=1, type=int,\n",
    "                    help='seed for initializing training')\n",
    "parser.add_argument('--dataset', default=\"krkp\", type=str,\n",
    "                    help='db')\n",
    "parser.add_argument('--select_ratio', default=0, type=float,\n",
    "                    help='confidence example selection ratio')\n",
    "parser.add_argument('--pretrained', default=0, type=int,\n",
    "                    help='using pretrained model or not')\n",
    "\n",
    "\n",
    "# added by yz:\n",
    "# parser.add_argument('--pca_k', type=int, default=5,\n",
    "#                     help='PCA dimension (default: 5)')\n",
    "# parser.add_argument('--sample_size', type=int, default=20,\n",
    "#                     help='randomly select samples for analysis')\n",
    "# parser.add_argument('--near_percentage', type=float, default=0.1,\n",
    "#                     help='percentage nearby in terms of L2 norm')\n",
    "'''\n",
    "Backbone Net Configurations\n",
    "'''\n",
    "parser.add_argument('--net', type=str, default='WideResNet')\n",
    "parser.add_argument('--net_from_name', type=bool, default=False)\n",
    "parser.add_argument('--depth', type=int, default=28)\n",
    "parser.add_argument('--widen_factor', type=int, default=2)\n",
    "parser.add_argument('--leaky_slope', type=float, default=0.1)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "\n",
    "\n",
    "arch_dict = {\"FashionMNIST\": \"resnet18\", \"cifar10\": \"resnet18\", \"cifar100\": \"resnet34\", \"mnist\": \"Lenet\",\n",
    "             \"balancescale\": \"NaiveNet\", \"krkp\": \"NaiveNet\", \"splice\": \"NaiveNet\", \"yxguassian\": \"NaiveNet\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clean_label': array([19, 29,  0, ...,  3,  7, 73]),\n",
       " 'noisy_label': array([19, 63, 10, ..., 64, 24, 95]),\n",
       " 'noisy_coarse_label': array([14, 12, 18, ..., 12,  7,  4]),\n",
       " 'clean_coarse_label': array([14, 15,  4, ..., 18,  7,  1])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test cifar10n\n",
    "\n",
    "cifar10n=torch.load('cifar-10-100n/data/CIFAR-100_human.pt')\n",
    "\n",
    "cifar10n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, epochs=10, z_dim=25, num_hidden_layers=2, flip_rate_fixed=0.4, train_frac=1.0, noise_type='sym', trainval_split=0.8, seed=1, dataset='cifar10', select_ratio=0, pretrained=0, net='WideResNet', net_from_name=False, depth=28, widen_factor=2, leaky_slope=0.1, dropout=0.0)\n",
      "=> preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load dataset\n",
    "\n",
    "from mylib.data.data_loader.load_cifardata import load_cifardata\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[\"--dataset\",\"cifar10\"])\n",
    "base_dir = \"./\"+args.dataset+\"/\"+args.noise_type + \\\n",
    "    str(args.flip_rate_fixed)+\"/\"+str(args.seed)+\"/\"\n",
    "print(args)\n",
    "if args.dataset == \"cifar10\":\n",
    "    if args.seed is not None:\n",
    "        fix_seed(args.seed)\n",
    "        train_val_loader, train_loader, val_loader, est_loader, test_loader = load_cifardata(\n",
    "            dataset=args.dataset, \n",
    "            random_state=args.seed,\n",
    "            add_noise=True,\n",
    "            batch_size=args.batch_size, \n",
    "            train_frac=args.train_frac, \n",
    "            trainval_split=args.trainval_split, \n",
    "            noise_type=args.noise_type, \n",
    "            flip_rate_fixed=args.flip_rate_fixed, \n",
    "            augment=False\n",
    "        )\n",
    "elif args.dataset == \"\":\n",
    "    pass\n",
    "else:\n",
    "    if args.seed is not None:\n",
    "        fix_seed(args.seed)\n",
    "        train_val_loader, train_loader, val_loader, est_loader, test_loader = load_ucidata(\n",
    "        dataset=args.dataset,\n",
    "        noise_type=args.noise_type,\n",
    "        random_state=args.seed,\n",
    "        batch_size=args.batch_size,\n",
    "        add_noise=True,\n",
    "        flip_rate_fixed=args.flip_rate_fixed,\n",
    "        trainval_split=args.trainval_split,\n",
    "        train_frac=args.train_frac,\n",
    "        augment=False\n",
    "    )\n",
    "# test_dataset = test_loader.dataset\n",
    "val_dataset = val_loader.dataset\n",
    "train_val_dataset = train_val_loader.dataset\n",
    "train_dataset = train_loader.dataset\n",
    "#print(\"training set length is: \"+str(len(train_dataset.dataset.data)))\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset.data.shape\n",
    "#train_dataset.dataset.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mylib.data.data_loader.subset import Dataset\n",
    "class BasicDataset(Dataset):\n",
    "    \"\"\"\n",
    "    BasicDataset returns a pair of image and labels (targets).\n",
    "    If targets are not given, BasicDataset returns None as the label.\n",
    "    This class supports strong augmentation for Fixmatch,\n",
    "    and return both weakly and strongly augmented images.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 targets=None,\n",
    "                 num_classes=None,\n",
    "                 transform=None,\n",
    "                 use_strong_transform=False,\n",
    "                 strong_transform=None,\n",
    "                 onehot=False,\n",
    "                 *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            data: x_data\n",
    "            targets: y_data (if not exist, None)\n",
    "            num_classes: number of label classes\n",
    "            transform: basic transformation of data\n",
    "            use_strong_transform: If True, this dataset returns both weakly and strongly augmented images.\n",
    "            strong_transform: list of transformation functions for strong augmentation\n",
    "            onehot: If True, label is converted into onehot vector.\n",
    "        \"\"\"\n",
    "        super(BasicDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.use_strong_transform = use_strong_transform\n",
    "        self.onehot = onehot\n",
    "        \n",
    "        self.transform = transform\n",
    "        if use_strong_transform:\n",
    "            pass\n",
    "        else:\n",
    "            self.strong_transform = strong_transform\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import sampler, DataLoader\n",
    "mean, std = {}, {}\n",
    "mean['cifar10'] = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "mean['cifar100'] = [x / 255 for x in [129.3, 124.1, 112.4]]\n",
    "mean['stl10'] = [0.485, 0.456, 0.406]\n",
    "mean['npy'] = [0.485, 0.456, 0.406]\n",
    "mean['npy224'] = [0.485, 0.456, 0.406]\n",
    "\n",
    "std['cifar10'] = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "std['cifar100'] = [x / 255 for x in [68.2,  65.4,  70.4]]\n",
    "std['stl10'] = [0.229, 0.224, 0.225]\n",
    "std['npy'] = [0.229, 0.224, 0.225]\n",
    "std['npy224'] = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "def get_dset(data,targets, num_classes, name, train, use_strong_transform=False, \n",
    "                strong_transform=None, onehot=False):\n",
    "    \"\"\"\n",
    "    get_dset returns class BasicDataset, containing the returns of get_data.\n",
    "    \n",
    "    Args\n",
    "        use_strong_tranform: If True, returned dataset generates a pair of weak and strong augmented images.\n",
    "        strong_transform: list of strong_transform (augmentation) if use_strong_transform is True\n",
    "        onehot: If True, the label is not integer, but one-hot vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    transform = get_transform(mean[name], std[name], name, train)\n",
    "    \n",
    "    return BasicDataset(data, targets, num_classes, transform, \n",
    "                        use_strong_transform, strong_transform, onehot)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def get_transform(mean, std, dataset, train=True):\n",
    "    if dataset in ['cifar10', 'cifar20', 'cifar100']:\n",
    "        crop_size = 32\n",
    "    elif dataset in ['stl10', 'npy']:\n",
    "        crop_size = 96\n",
    "    elif dataset in ['npy224']:\n",
    "        crop_size = 224\n",
    "    else:\n",
    "        raise TypeError\n",
    "    if train:\n",
    "        return transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(crop_size, padding=4),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean, std)])\n",
    "    else:\n",
    "        return transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean, std)])\n",
    "        \n",
    "def get_data_loader(dset,\n",
    "                    batch_size = None,\n",
    "                    shuffle = False,\n",
    "                    num_workers = 4,\n",
    "                    pin_memory = True,\n",
    "                    data_sampler = None,\n",
    "                    replacement = True,\n",
    "                    num_epochs = None,\n",
    "                    num_iters = None,\n",
    "                    generator = None,\n",
    "                    drop_last=True,\n",
    "                    distributed=False):\n",
    "    \"\"\"\n",
    "    get_data_loader returns torch.utils.data.DataLoader for a Dataset.\n",
    "    All arguments are comparable with those of pytorch DataLoader.\n",
    "    However, if distributed, DistributedProxySampler, which is a wrapper of data_sampler, is used.\n",
    "    \n",
    "    Args\n",
    "        num_epochs: total batch -> (# of batches in dset) * num_epochs \n",
    "        num_iters: total batch -> num_iters\n",
    "    \"\"\"\n",
    "    \n",
    "    assert batch_size is not None\n",
    "        \n",
    "    if data_sampler is None:\n",
    "        return DataLoader(dset, batch_size=batch_size, shuffle=shuffle, \n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n",
    "    \n",
    "    # else:\n",
    "    #     if isinstance(data_sampler, str):\n",
    "    #         data_sampler = get_sampler_by_name(data_sampler)\n",
    "        \n",
    "    #     if distributed:\n",
    "    #         assert dist.is_available()\n",
    "    #         num_replicas = dist.get_world_size()\n",
    "    #     else:\n",
    "    #         num_replicas = 1\n",
    "        \n",
    "    #     if (num_epochs is not None) and (num_iters is None):\n",
    "    #         num_samples = len(dset)*num_epochs\n",
    "    #     elif (num_epochs is None) and (num_iters is not None):\n",
    "    #         num_samples = batch_size * num_iters * num_replicas\n",
    "    #     else:\n",
    "    #         num_samples = len(dset)\n",
    "        \n",
    "    #     if data_sampler.__name__ == 'RandomSampler':    \n",
    "    #         data_sampler = data_sampler(dset, replacement, num_samples, generator)\n",
    "    #     else:\n",
    "    #         raise RuntimeError(f\"{data_sampler.__name__} is not implemented.\")\n",
    "        \n",
    "    #     if distributed:\n",
    "    #         '''\n",
    "    #         Different with DistributedSampler, \n",
    "    #         the DistribuedProxySampler does not shuffle the data (just wrapper for dist).\n",
    "    #         '''\n",
    "    #         data_sampler = DistributedProxySampler(data_sampler)\n",
    "\n",
    "    #     batch_sampler = BatchSampler(data_sampler, batch_size, drop_last)\n",
    "    #     return DataLoader(dset, batch_sampler=batch_sampler, \n",
    "    #                       num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dest = get_dset(train_dataset.dataset.data,train_dataset.dataset.targets,10,\"cifar10\",True)\n",
    "\n",
    "my_data_loader=get_data_loader(my_data_dest,batch_size=args.batch_size,num_workers=1)\n",
    "\n",
    "\n",
    "# my_data_loader = train_val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_loader.dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth in <fixmatch.models.nets.wrn.build_WideResNet object at 0x16764fe80> is overlapped by kwargs: 28 -> 28\n",
      "widen_factor in <fixmatch.models.nets.wrn.build_WideResNet object at 0x16764fe80> is overlapped by kwargs: 2 -> 2\n",
      "leaky_slope in <fixmatch.models.nets.wrn.build_WideResNet object at 0x16764fe80> is overlapped by kwargs: 0.0 -> 0.1\n",
      "dropRate in <fixmatch.models.nets.wrn.build_WideResNet object at 0x16764fe80> is overlapped by kwargs: 0.0 -> 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WideResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block3): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model = torch.load('model_cifar10_cls.pth',map_location=torch.device('cpu'))\n",
    "\n",
    "from fixmatch.utils import *\n",
    "_net_builder = net_builder(args.net,\n",
    "                                   args.net_from_name,\n",
    "                                   {'depth': args.depth,\n",
    "                                    'widen_factor': args.widen_factor,\n",
    "                                    'leaky_slope': args.leaky_slope,\n",
    "                                    'dropRate': args.dropout})\n",
    "\n",
    "net = _net_builder(num_classes=10)\n",
    "net.load_state_dict(load_model,strict=False)\n",
    "\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_acc(ypred, y, return_idx=False):\n",
    "    \"\"\"\n",
    "    Calculating the clustering accuracy. The predicted result must have the same number of clusters as the ground truth.\n",
    "\n",
    "    ypred: 1-D numpy vector, predicted labels\n",
    "    y: 1-D numpy vector, ground truth\n",
    "    The problem of finding the best permutation to calculate the clustering accuracy is a linear assignment problem.\n",
    "    This function construct a N-by-N cost matrix, then pass it to scipy.optimize.linear_sum_assignment to solve the assignment problem.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(y) > 0\n",
    "    assert len(np.unique(ypred)) == len(np.unique(y))\n",
    "\n",
    "    s = np.unique(ypred)\n",
    "    t = np.unique(y)\n",
    "\n",
    "    N = len(np.unique(ypred))\n",
    "    C = np.zeros((N, N), dtype=np.int32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            idx = np.logical_and(ypred == s[i], y == t[j])\n",
    "            C[i][j] = np.count_nonzero(idx)\n",
    "\n",
    "    # convert the C matrix to the 'true' cost\n",
    "    Cmax = np.amax(C)\n",
    "    C = Cmax - C\n",
    "    row, col = linear_sum_assignment(C)\n",
    "    # calculating the accuracy according to the optimal assignment\n",
    "    count = 0\n",
    "    for i in range(N):\n",
    "        idx = np.logical_and(ypred == s[row[i]], y == t[col[i]])\n",
    "        count += np.count_nonzero(idx)\n",
    "\n",
    "    if return_idx:\n",
    "        return 1.0 * count / len(y), row, col\n",
    "    else:\n",
    "        return 1.0 * count / len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Users/yangz/miniforge3/envs/al/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Users/yangz/miniforge3/envs/al/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'BasicDataset' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m scores \u001b[39m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mfor\u001b[39;00m image, label \u001b[39min\u001b[39;00m my_data_loader:\n\u001b[1;32m      7\u001b[0m         \u001b[39m#image = image.type(torch.FloatTensor).cuda()\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=====\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m         logit \u001b[39m=\u001b[39m net(image)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torch/utils/data/dataloader.py:435\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[1;32m    434\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 435\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torch/utils/data/dataloader.py:381\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1034\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m   1027\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[1;32m   1035\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[1;32m   1036\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/multiprocessing/context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m--> 224\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_posix\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fds \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(process_obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfinalizer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_launch(process_obj)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentinel \u001b[39m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(parent_w, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m, closefd\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         f\u001b[39m.\u001b[39;49mwrite(fp\u001b[39m.\u001b[39;49mgetbuffer())\n\u001b[1;32m     63\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "acc = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    for image, label in my_data_loader:\n",
    "        #image = image.type(torch.FloatTensor).cuda()\n",
    "        print(\"=====\")\n",
    "        logit = net(image)\n",
    "\n",
    "        scores.append(logit.cpu().numpy())\n",
    "\n",
    "        labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "        labels_gt.append(label.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "# save labels added by yz\n",
    "#np.save(\"labels_pred.npy\", labels_pred)\n",
    "\n",
    "try:\n",
    "    acc = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "\n",
    "#nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "#ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc}\")   #, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "if args.scores_path is not None:\n",
    "    np.save(args.scores_path, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [78], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx2 \u001b[39m=\u001b[39m _hungarian_match(labels_pred, train_dataset\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mtargets)\n\u001b[0;32m----> 2\u001b[0m prime_Y \u001b[39m=\u001b[39m get_prime_Y(train_dataset\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mtargets, labels_pred, idx2[\u001b[39m1\u001b[39;49m])\n\u001b[1;32m      4\u001b[0m \u001b[39m#train_loader.dataset.dataset.targets[0]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m prime_Y\n",
      "Cell \u001b[0;32mIn [23], line 22\u001b[0m, in \u001b[0;36mget_prime_Y\u001b[0;34m(noisy_classes, pred_classes, mappings)\u001b[0m\n\u001b[1;32m     20\u001b[0m prime_Y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mlen\u001b[39m(noisy_classes))\n\u001b[1;32m     21\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(pred_classes)):\n\u001b[0;32m---> 22\u001b[0m     prime_Y[i] \u001b[39m=\u001b[39m mappings[pred_classes[i]]\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m prime_Y\n",
      "\u001b[0;31mIndexError\u001b[0m: index 7 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "idx2 = _hungarian_match(labels_pred, train_dataset.dataset.targets)\n",
    "prime_Y = get_prime_Y(train_dataset.dataset.targets, labels_pred, idx2[1])\n",
    "\n",
    "#train_loader.dataset.dataset.targets[0]\n",
    "prime_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compare with Y prime, error rate is : 0.642\n",
      "compare with Y prime, error rate is : 0.608\n",
      "compare with Y prime, error rate is : 0.63\n",
      "compare with Y prime, error rate is : 0.664\n",
      "compare with Y prime, error rate is : 0.664\n",
      "compare with Y prime, error rate is : 0.664\n",
      "compare with Y prime, error rate is : 0.646\n",
      "compare with Y prime, error rate is : 0.666\n",
      "compare with Y prime, error rate is : 0.664\n"
     ]
    }
   ],
   "source": [
    "initial_noise_labels = train_dataset.dataset.targets\n",
    "num_classes = train_dataset.dataset._get_num_classes()\n",
    "primeY = run_kmeans2(train_dataset.dataset)\n",
    "\n",
    "train_labels = initial_noise_labels.copy()\n",
    "train_labels = train_labels[:,np.newaxis]\n",
    "\n",
    "error_list = []\n",
    "noise_list = np.arange(0.1, 1, 0.1)\n",
    "for noise_rate in noise_list:\n",
    "    train_noisy_labels, _, _ = noisify_multiclass_symmetric(initial_noise_labels.copy()[:,np.newaxis], noise_rate, random_state=args.seed, nb_classes=num_classes)\n",
    "    # sanity check on label noise rate\n",
    "    # res1 = (initial_noise_labels == train_noisy_labels[:,0])\n",
    "    # count1 = collections.Counter(res1)\n",
    "    # label_noise_rate = count1[False]/(count1[False]+count1[True])\n",
    "    # print(\"after adding noise, the noise rate is: \"+str(label_noise_rate))\n",
    "    \n",
    "    # calcualte error rate on the noisy labels\n",
    "    res2 = (primeY == train_noisy_labels[:,0])\n",
    "    count2 = collections.Counter(res2)\n",
    "    error_rate = count2[False]/(count2[False]+count2[True])\n",
    "    print(\"compare with Y prime, error rate is : \"+str(error_rate))\n",
    "    error_list.append(error_rate)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(noise_list, error_list)\n",
    "plt.ylim(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Load data ---- #\n",
    "\n",
    "noisy_data_list = []\n",
    "noisy_rate_list = np.arange(0.1, 1, 0.2)\n",
    "\n",
    "for rate in noisy_rate_list:\n",
    "    train_loader = load_ucidata2(\n",
    "        dataset=args.dataset,\n",
    "        noise_type=\"sym\",\n",
    "        random_state=args.seed,\n",
    "        batch_size=args.batch_size,\n",
    "        add_noise=True,\n",
    "        flip_rate_fixed=rate,\n",
    "        trainval_split=args.trainval_split,\n",
    "        train_frac=args.train_frac,\n",
    "        augment=False\n",
    "    )\n",
    "\n",
    "    noisy_data_list.append(train_loader.dataset)\n",
    "\n",
    "# primeY is obtained from K-means unsupervised learning -> we use this as esitmated Clean Y\n",
    "primeY = run_kmeans2(train_dataset.dataset)\n",
    "\n",
    "error_list = []\n",
    "for i in range(len(noisy_data_list)):\n",
    "    noisy_data = noisy_data_list[i]\n",
    "    noisy_Y = noisy_data.dataset.targets\n",
    "    res = (primeY == noisy_Y)\n",
    "    count = collections.Counter(res)\n",
    "    error_rate = count[False]/(count[False]+count[True])\n",
    "    error_list.append(error_rate)\n",
    "\n",
    "df = pd.concat([pd.DataFrame(noisy_rate_list),\n",
    "                pd.DataFrame(error_list)], axis=1)\n",
    "df.columns = ['noisy_rate', 'error_rate']\n",
    "\n",
    "df['dataset'] = args.dataset\n",
    "\n",
    "df['noise_type'] = args.noise_type\n",
    "# if dataset in \"krkp\", \"balancescale\", \"splice\", \"xyguassian\" then it is causal\n",
    "df['causal'] = df['dataset'].apply(\n",
    "    lambda x: 1 if x in [\"krkp\", \"balancescale\", \"splice\", \"xyguassian\"] else 0)\n",
    "df['inital_noise'] = args.flip_rate_fixed\n",
    "df['seed'] = args.seed\n",
    "df.to_csv('./results/results_method1_error_rate.csv',\n",
    "            mode='a', index=False, header=False)\n",
    "\n",
    "print(\"all done\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "410387e4bb6056df1e8fba72755cd1379fbde9775ae114a23afab7a71b2c10e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

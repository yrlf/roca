{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import imp\n",
    "from random import seed\n",
    "from mylib.utils import fix_seed\n",
    "from mylib.data.data_loader import load_ucidata\n",
    "import collections\n",
    "import numpy as np\n",
    "from run_dnl import run_dnl\n",
    "import tools\n",
    "import pandas as pd\n",
    "from kmeans import run_kmeans\n",
    "import os\n",
    "import argparse\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "# adjust the load data function to load training data only\n",
    "from mylib.data.data_loader.load_ucidata import load_ucidata2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import BatchSampler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.metrics import accuracy_score\n",
    "from cal_acc import *\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from mylib.data.dataset.util import noisify_multiclass_symmetric\n",
    "\n",
    "from mylib.data.data_loader.subset import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import sampler, DataLoader\n",
    "from mylib.data.data_loader.load_cifardata import load_cifardata\n",
    "from mylib.data.data_loader.load_mnistdata import load_mnistdata\n",
    "import mylib.data.dataset\n",
    "\n",
    "from fixmatch.datasets.ssl_dataset_robust import SSL_Dataset\n",
    "from fixmatch.datasets.data_utils import get_data_loader\n",
    "from fixmatch.datasets.dataset_robust import *\n",
    "from mylib.data.data_loader.subset import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import sampler, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in data/Imagenet/.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imagenet_data \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mImageNet(\u001b[39m'\u001b[39;49m\u001b[39mdata/Imagenet/\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:46\u001b[0m, in \u001b[0;36mImageNet.__init__\u001b[0;34m(self, root, split, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m root \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexpanduser(root)\n\u001b[1;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit \u001b[39m=\u001b[39m verify_str_arg(split, \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m, (\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> 46\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_archives()\n\u001b[1;32m     47\u001b[0m wnid_to_classes \u001b[39m=\u001b[39m load_meta_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_folder, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:59\u001b[0m, in \u001b[0;36mImageNet.parse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_archives\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     58\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_integrity(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, META_FILE)):\n\u001b[0;32m---> 59\u001b[0m         parse_devkit_archive(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[1;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit_folder):\n\u001b[1;32m     62\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msplit \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:140\u001b[0m, in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    137\u001b[0m     file \u001b[39m=\u001b[39m archive_meta[\u001b[39m0\u001b[39m]\n\u001b[1;32m    138\u001b[0m md5 \u001b[39m=\u001b[39m archive_meta[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 140\u001b[0m _verify_archive(root, file, md5)\n\u001b[1;32m    142\u001b[0m \u001b[39mwith\u001b[39;00m get_tmp_dir() \u001b[39mas\u001b[39;00m tmp_dir:\n\u001b[1;32m    143\u001b[0m     extract_archive(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file), tmp_dir)\n",
      "File \u001b[0;32m~/miniforge3/envs/al/lib/python3.9/site-packages/torchvision/datasets/imagenet.py:96\u001b[0m, in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m check_integrity(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(root, file), md5):\n\u001b[1;32m     92\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m     93\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe archive \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m is not present in the root directory or is corrupted. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou need to download it externally and place it in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(file, root))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in data/Imagenet/."
     ]
    }
   ],
   "source": [
    "imagenet_data = torchvision.datasets.ImageNet('data/Imagenet/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _hungarian_match(flat_preds, flat_targets):\n",
    "    # Based on implementation from IIC\n",
    "    num_samples = flat_targets.shape[0]\n",
    "    v, counts = np.unique(flat_preds, return_counts=True)\n",
    "\n",
    "    num_k = len(v)\n",
    "    num_correct = np.zeros((num_k, num_k))\n",
    "\n",
    "    for c1 in range(num_k):\n",
    "        for c2 in range(num_k):\n",
    "            # elementwise, so each sample contributes once\n",
    "            votes = int(((flat_preds == c1) * (flat_targets == c2)).sum())\n",
    "            num_correct[c1, c2] = votes\n",
    "\n",
    "    row, col = linear_sum_assignment(num_samples - num_correct)\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def get_prime_Y(noisy_classes, pred_classes, mappings):\n",
    "    prime_Y = np.zeros(len(noisy_classes))\n",
    "    for i in range(len(pred_classes)):\n",
    "        prime_Y[i] = mappings[pred_classes[i]]\n",
    "\n",
    "    return prime_Y\n",
    "\n",
    "\n",
    "\n",
    "def run_kmeans2(dataset):\n",
    "\n",
    "    X = dataset.data\n",
    "    clean_Y = dataset.clean_targets\n",
    "    tilde_Y = dataset.targets\n",
    "    values, counts = np.unique(clean_Y, return_counts=True)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=len(values))\n",
    "    kmeans.fit(X, tilde_Y)\n",
    "    identified_clusters = kmeans.fit_predict(X)\n",
    "\n",
    "    # note that to better match the cluster Id to tilde_Y,\n",
    "    # we could use hat_clean Y which obtained by current noise-robust method, but for the simple dataset , it may not necessary\n",
    "\n",
    "    idx2 = _hungarian_match(identified_clusters, tilde_Y)\n",
    "    prime_Y = get_prime_Y(tilde_Y, identified_clusters, idx2[1])\n",
    "    # yz: directly return prime_Y without using count_m\n",
    "    return prime_Y\n",
    "\n",
    "\n",
    "\n",
    "# --- parsing and configuration --- #\n",
    "parser = argparse.ArgumentParser(\n",
    "    description=\"PyTorch implementation of VAE\")\n",
    "parser.add_argument('--batch_size', type=int, default=16,\n",
    "                    help='batch size for training (default: 128)')\n",
    "parser.add_argument('--epochs', type=int, default=10,\n",
    "                    help='number of epochs to train (default: 20)')\n",
    "parser.add_argument('--z_dim', type=int, default=25,\n",
    "                    help='dimension of hidden variable Z (default: 10)')\n",
    "parser.add_argument('--num_hidden_layers', type=int, default=2,\n",
    "                    help='num hidden_layers (default: 0)')\n",
    "parser.add_argument('--flip_rate_fixed', type=float,\n",
    "                    help='fixed flip rates.', default=0.01)\n",
    "parser.add_argument('--train_frac', default=1.0, type=float,\n",
    "                    help='training sample size fraction')\n",
    "parser.add_argument('--noise_type', type=str, default='sym')\n",
    "parser.add_argument('--trainval_split',  default=0.8, type=float,\n",
    "                    help='training set ratio')\n",
    "parser.add_argument('--seed', default=1, type=int,\n",
    "                    help='seed for initializing training')\n",
    "parser.add_argument('--dataset', default=\"krkp\", type=str,\n",
    "                    help='db')\n",
    "parser.add_argument('--select_ratio', default=0, type=float,\n",
    "                    help='confidence example selection ratio')\n",
    "parser.add_argument('--pretrained', default=0, type=int,\n",
    "                    help='using pretrained model or not')\n",
    "\n",
    "\n",
    "# added by yz:\n",
    "# parser.add_argument('--pca_k', type=int, default=5,\n",
    "#                     help='PCA dimension (default: 5)')\n",
    "# parser.add_argument('--sample_size', type=int, default=20,\n",
    "#                     help='randomly select samples for analysis')\n",
    "# parser.add_argument('--near_percentage', type=float, default=0.1,\n",
    "#                     help='percentage nearby in terms of L2 norm')\n",
    "'''\n",
    "Backbone Net Configurations\n",
    "'''\n",
    "parser.add_argument('--net', type=str, default='WideResNet')\n",
    "parser.add_argument('--net_from_name', type=bool, default=False)\n",
    "parser.add_argument('--depth', type=int, default=28)\n",
    "parser.add_argument('--widen_factor', type=int, default=2)\n",
    "parser.add_argument('--leaky_slope', type=float, default=0.1)\n",
    "parser.add_argument('--dropout', type=float, default=0.0)\n",
    "\n",
    "'''\n",
    "Data Configurations\n",
    "'''\n",
    "#parser.add_argument('--batch_size', type=int, default=100)\n",
    "parser.add_argument('--data_dir', type=str, default='./datasets/cifar-10-batches-py')\n",
    "#parser.add_argument('--dataset', type=str, default='cifar10')\n",
    "parser.add_argument('--num_classes', type=int, default=10)\n",
    "parser.add_argument('--label_file', type=str, default=None)\n",
    "parser.add_argument('--all', type=int, default=0)\n",
    "parser.add_argument('--unlabeled', type=bool, default=False)\n",
    "\n",
    "\n",
    "arch_dict = {\"FashionMNIST\": \"resnet18\", \"cifar10\": \"resnet18\", \"cifar100\": \"resnet34\", \"mnist\": \"Lenet\",\n",
    "             \"balancescale\": \"NaiveNet\", \"krkp\": \"NaiveNet\", \"splice\": \"NaiveNet\", \"yxguassian\": \"NaiveNet\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=16, epochs=10, z_dim=25, num_hidden_layers=2, flip_rate_fixed=0.01, train_frac=1.0, noise_type='sym', trainval_split=0.8, seed=2, dataset='cifar10', select_ratio=0, pretrained=0, net='WideResNet', net_from_name=False, depth=28, widen_factor=2, leaky_slope=0.1, dropout=0.0, data_dir='./datasets/cifar-10-batches-py', num_classes=10, label_file=None, all=0, unlabeled=False)\n",
      "=> preparing data..\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "args = parser.parse_args(args=[\"--dataset\",\"cifar10\",\"--seed\",\"2\"])\n",
    "base_dir = \"./\"+args.dataset+\"/\"+args.noise_type + \\\n",
    "    str(args.flip_rate_fixed)+\"/\"+str(args.seed)+\"/\"\n",
    "print(args)\n",
    "if args.dataset == \"cifar10\":\n",
    "    if args.seed is not None:\n",
    "        fix_seed(args.seed)\n",
    "        train_val_loader, train_loader, val_loader, est_loader, test_loader = load_cifardata(\n",
    "            dataset=args.dataset, \n",
    "            random_state=args.seed,\n",
    "            add_noise=True,\n",
    "            batch_size=args.batch_size, \n",
    "            train_frac=args.train_frac, \n",
    "            trainval_split=args.trainval_split, \n",
    "            noise_type=args.noise_type, \n",
    "            flip_rate_fixed=args.flip_rate_fixed, \n",
    "            augment=False\n",
    "        )\n",
    "        \n",
    "else:\n",
    "    if args.seed is not None:\n",
    "        fix_seed(args.seed)\n",
    "        train_val_loader, train_loader, val_loader, est_loader, test_loader = load_ucidata(\n",
    "        dataset=args.dataset,\n",
    "        noise_type=args.noise_type,\n",
    "        random_state=args.seed,\n",
    "        batch_size=args.batch_size,\n",
    "        add_noise=True,\n",
    "        flip_rate_fixed=args.flip_rate_fixed,\n",
    "        trainval_split=args.trainval_split,\n",
    "        train_frac=args.train_frac,\n",
    "        augment=False\n",
    "    )\n",
    "# test_dataset = test_loader.dataset\n",
    "val_dataset = val_loader.dataset\n",
    "train_val_dataset = train_val_loader.dataset\n",
    "train_dataset = train_loader.dataset\n",
    "#print(\"training set length is: \"+str(len(train_dataset.dataset.data)))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.dataset.data.shape\n",
    "\n",
    "#np.unique(train_dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDataset(Dataset):\n",
    "    \"\"\"\n",
    "    BasicDataset returns a pair of image and labels (targets).\n",
    "    If targets are not given, BasicDataset returns None as the label.\n",
    "    This class supports strong augmentation for Fixmatch,\n",
    "    and return both weakly and strongly augmented images.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 targets=None,\n",
    "                 num_classes=None,\n",
    "                 transform=None,\n",
    "                 use_strong_transform=False,\n",
    "                 strong_transform=None,\n",
    "                 onehot=False,\n",
    "                 *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Args\n",
    "            data: x_data\n",
    "            targets: y_data (if not exist, None)\n",
    "            num_classes: number of label classes\n",
    "            transform: basic transformation of data\n",
    "            use_strong_transform: If True, this dataset returns both weakly and strongly augmented images.\n",
    "            strong_transform: list of transformation functions for strong augmentation\n",
    "            onehot: If True, label is converted into onehot vector.\n",
    "        \"\"\"\n",
    "        super(BasicDataset, self).__init__()\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.use_strong_transform = use_strong_transform\n",
    "        self.onehot = onehot\n",
    "        \n",
    "        self.transform = transform\n",
    "        if use_strong_transform:\n",
    "            if strong_transform is None:\n",
    "                self.strong_transform = copy.deepcopy(transform)\n",
    "                self.strong_transform.transforms.insert(0, RandAugment(3,5))\n",
    "        else:\n",
    "            self.strong_transform = strong_transform\n",
    "                \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        If strong augmentation is not used,\n",
    "            return weak_augment_image, target\n",
    "        else:\n",
    "            return weak_augment_image, strong_augment_image, target\n",
    "        \"\"\"\n",
    "        \n",
    "        #set idx-th target\n",
    "        if self.targets is None:\n",
    "            target = None\n",
    "        else:\n",
    "            target_ = self.targets[idx]\n",
    "            target = target_ if not self.onehot else get_onehot(self.num_classes, target_)\n",
    "            \n",
    "        #set augmented images\n",
    "            \n",
    "        img = self.data[idx]\n",
    "        if self.transform is None:\n",
    "            return transforms.ToTensor()(img), target\n",
    "        else:\n",
    "            if isinstance(img, np.ndarray):\n",
    "                img = Image.fromarray(img)\n",
    "            img_w = self.transform(img)\n",
    "            if not self.use_strong_transform:\n",
    "                return img_w, target, idx\n",
    "            else:\n",
    "                return img_w, self.strong_transform(img), target\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean, std = {}, {}\n",
    "mean['cifar10'] = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "mean['cifar100'] = [x / 255 for x in [129.3, 124.1, 112.4]]\n",
    "mean['stl10'] = [0.485, 0.456, 0.406]\n",
    "mean['npy'] = [0.485, 0.456, 0.406]\n",
    "mean['npy224'] = [0.485, 0.456, 0.406]\n",
    "mean['FashionMNIST'] = [0.2860]\n",
    "\n",
    "\n",
    "std['cifar10'] = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "std['cifar100'] = [x / 255 for x in [68.2,  65.4,  70.4]]\n",
    "std['stl10'] = [0.229, 0.224, 0.225]\n",
    "std['npy'] = [0.229, 0.224, 0.225]\n",
    "std['npy224'] = [0.229, 0.224, 0.225]\n",
    "std['FashionMNIST'] = [0.3530]\n",
    "\n",
    "def get_dset(data,targets, num_classes, name, train, use_strong_transform=False, \n",
    "                strong_transform=None, onehot=False):\n",
    "    \"\"\"\n",
    "    get_dset returns class BasicDataset, containing the returns of get_data.\n",
    "    \n",
    "    Args\n",
    "        use_strong_tranform: If True, returned dataset generates a pair of weak and strong augmented images.\n",
    "        strong_transform: list of strong_transform (augmentation) if use_strong_transform is True\n",
    "        onehot: If True, the label is not integer, but one-hot vector.\n",
    "    \"\"\"\n",
    "    \n",
    "    transform = get_transform(mean[name], std[name], name, train)\n",
    "    \n",
    "    return BasicDataset(data, targets, num_classes, transform, \n",
    "                        use_strong_transform, strong_transform, onehot)\n",
    "    \n",
    "\n",
    "    \n",
    "def get_transform(mean, std, dataset, train=True):\n",
    "    if dataset in ['cifar10', 'cifar20', 'cifar100']:\n",
    "        crop_size = 32\n",
    "    elif dataset in ['stl10', 'npy']:\n",
    "        crop_size = 96\n",
    "    elif dataset in ['FashionMNIST']:\n",
    "        crop_size = 28\n",
    "    elif dataset in ['npy224']:\n",
    "        crop_size = 224\n",
    "    else:\n",
    "        raise TypeError\n",
    "    if train:\n",
    "        return transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.RandomCrop(crop_size, padding=4),\n",
    "                                    transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean, std)])\n",
    "    else:\n",
    "        return transforms.Compose([transforms.ToTensor(), \n",
    "                                    transforms.Normalize(mean, std)])\n",
    "        \n",
    "def get_data_loader(dset,\n",
    "                    batch_size = None,\n",
    "                    shuffle = False,\n",
    "                    num_workers = 4,\n",
    "                    pin_memory = True,\n",
    "                    data_sampler = None,\n",
    "                    replacement = True,\n",
    "                    num_epochs = None,\n",
    "                    num_iters = None,\n",
    "                    generator = None,\n",
    "                    drop_last=True,\n",
    "                    distributed=False):\n",
    "    \"\"\"\n",
    "    get_data_loader returns torch.utils.data.DataLoader for a Dataset.\n",
    "    All arguments are comparable with those of pytorch DataLoader.\n",
    "    However, if distributed, DistributedProxySampler, which is a wrapper of data_sampler, is used.\n",
    "    \n",
    "    Args\n",
    "        num_epochs: total batch -> (# of batches in dset) * num_epochs \n",
    "        num_iters: total batch -> num_iters\n",
    "    \"\"\"\n",
    "    \n",
    "    assert batch_size is not None\n",
    "        \n",
    "    if data_sampler is None:\n",
    "        return DataLoader(dset, batch_size=batch_size, shuffle=shuffle, \n",
    "                          num_workers=num_workers, pin_memory=pin_memory)\n",
    "    else:\n",
    "        print(\"data sample is not implmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth in <fixmatch.models.nets.wrn.build_WideResNet object at 0x2c87e6cd0> is overlapped by kwargs: 28 -> 28\n",
      "widen_factor in <fixmatch.models.nets.wrn.build_WideResNet object at 0x2c87e6cd0> is overlapped by kwargs: 2 -> 2\n",
      "leaky_slope in <fixmatch.models.nets.wrn.build_WideResNet object at 0x2c87e6cd0> is overlapped by kwargs: 0.0 -> 0.1\n",
      "dropRate in <fixmatch.models.nets.wrn.build_WideResNet object at 0x2c87e6cd0> is overlapped by kwargs: 0.0 -> 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WideResNet(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (block1): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block2): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (block3): NetworkBlock(\n",
       "    (layer): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (convShortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (relu): LeakyReLU(negative_slope=0.1, inplace=True)\n",
       "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = torch.load('model_cifar10_cls.pth')\n",
    "model = torch.load('model_cifar10_cls.pth', map_location=torch.device('cpu'))\n",
    "load_model = model['train_model']\n",
    "for k in list(load_model.keys()):\n",
    "\n",
    "    # Initialize the feature module with encoder_q of moco.\n",
    "    if k.startswith('model.'):\n",
    "        # remove prefix\n",
    "        load_model[k[len('model.'):]] = load_model[k]\n",
    "\n",
    "        del load_model[k]\n",
    "        # print(k)\n",
    "\n",
    "from fixmatch.utils import *\n",
    "\n",
    "_net_builder = net_builder(args.net,\n",
    "                                   args.net_from_name,\n",
    "                                   {'depth': args.depth,\n",
    "                                    'widen_factor': args.widen_factor,\n",
    "                                    'leaky_slope': args.leaky_slope,\n",
    "                                    'dropRate': args.dropout})\n",
    "\n",
    "net = _net_builder(num_classes=10)\n",
    "net.load_state_dict(load_model,strict=False)\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "def calculate_acc(ypred, y, return_idx=False):\n",
    "    \"\"\"\n",
    "    Calculating the clustering accuracy. The predicted result must have the same number of clusters as the ground truth.\n",
    "\n",
    "    ypred: 1-D numpy vector, predicted labels\n",
    "    y: 1-D numpy vector, ground truth\n",
    "    The problem of finding the best permutation to calculate the clustering accuracy is a linear assignment problem.\n",
    "    This function construct a N-by-N cost matrix, then pass it to scipy.optimize.linear_sum_assignment to solve the assignment problem.\n",
    "\n",
    "    \"\"\"\n",
    "    assert len(y) > 0\n",
    "    assert len(np.unique(ypred)) == len(np.unique(y))\n",
    "\n",
    "    s = np.unique(ypred)\n",
    "    t = np.unique(y)\n",
    "\n",
    "    N = len(np.unique(ypred))\n",
    "    C = np.zeros((N, N), dtype=np.int32)\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            idx = np.logical_and(ypred == s[i], y == t[j])\n",
    "            C[i][j] = np.count_nonzero(idx)\n",
    "\n",
    "    # convert the C matrix to the 'true' cost\n",
    "    Cmax = np.amax(C)\n",
    "    C = Cmax - C\n",
    "    row, col = linear_sum_assignment(C)\n",
    "    # calculating the accuracy according to the optimal assignment\n",
    "    count = 0\n",
    "    for i in range(N):\n",
    "        idx = np.logical_and(ypred == s[row[i]], y == t[col[i]])\n",
    "        count += np.count_nonzero(idx)\n",
    "\n",
    "    if return_idx:\n",
    "        return 1.0 * count / len(y), row, col\n",
    "    else:\n",
    "        return 1.0 * count / len(y)\n",
    "\n",
    "\n",
    "def calculate_nmi(predict_labels, true_labels):\n",
    "    # NMI\n",
    "    nmi = metrics.normalized_mutual_info_score(\n",
    "        true_labels, predict_labels, average_method='geometric')\n",
    "    return nmi\n",
    "\n",
    "\n",
    "def calculate_ari(predict_labels, true_labels):\n",
    "    # ARI\n",
    "    ari = metrics.adjusted_rand_score(true_labels, predict_labels)\n",
    "    return ari\n",
    "\n",
    "\n",
    "\n",
    "use_own_data = True\n",
    "\n",
    "if (use_own_data and args.dataset == 'cifar10'):\n",
    "    my_data_dest = get_dset(train_dataset.dataset.data,train_dataset.dataset.targets,10,\"cifar10\",True)\n",
    "    my_data_loader=get_data_loader(my_data_dest,batch_size=args.batch_size,num_workers=0)\n",
    "    #my_data_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "    #my_data_loader = get_data_loader(my_data_dest, batch_size=args.batch_size, num_workers=1, shuffle=False)\n",
    "elif (use_own_data and args.dataset == 'FashionMNIST'):\n",
    "    #my_data_dest = get_dset(train_dataset.data,train_dataset.targets,10,\"FashionMNIST\",True)\n",
    "    #my_data_loader=get_data_loader(my_data_dest,batch_size=args.batch_size,num_workers=1)\n",
    "    pass\n",
    "else:\n",
    "    pass\n",
    "    # _eval_dset = SSL_Dataset(name=args.dataset, train=False, data_dir='/datasets/cifar-10-batches-py', label_file=None, all=args.all, unlabeled=False)\n",
    "    # eval_dset = _eval_dset.get_dset()\n",
    "    # my_data_loader = get_data_loader(eval_dset, args.batch_size, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "for i ,j,_ in my_data_loader:\n",
    "    print(i.shape)\n",
    "    print(j.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "Test Accuracy: 0.89892, NMI: 0.8160536722461319, ARI: 0.8022291185200308\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "acc = 0.0\n",
    "labels_pred = []\n",
    "labels_gt = []\n",
    "\n",
    "scores = []\n",
    "with torch.no_grad():\n",
    "    if args.dataset == \"FashionMNIST\":\n",
    "        # not used below\n",
    "        for i, (x, y) in enumerate(train_loader):\n",
    "            if torch.cuda.is_available():\n",
    "                x = x.cuda()\n",
    "            y_pred = net(x)\n",
    "            scores.append(y_pred)\n",
    "            labels_pred.append(torch.argmax(y_pred, dim=1).cpu().numpy())\n",
    "            labels_gt.append(y.cpu().numpy())\n",
    "    else:\n",
    "        print(\"===\")\n",
    "        for image, target,_ in my_data_loader:\n",
    "        #for image, target in train_dataset:\n",
    "            \n",
    "            \n",
    "            #image = image.type(torch.FloatTensor).cuda()\n",
    "        \n",
    "            #image = image.unsqueeze(0).type(torch.FloatTensor)\n",
    "            logit = net(image)\n",
    "\n",
    "            scores.append(logit.cpu().numpy())\n",
    "\n",
    "            labels_pred.append(torch.max(logit, dim=-1)[1].cpu().numpy())\n",
    "            labels_gt.append(target.cpu().numpy())\n",
    "\n",
    "scores = np.concatenate(scores, axis=0)\n",
    "labels_pred = np.concatenate(labels_pred, axis=0)\n",
    "labels_gt = np.concatenate(labels_gt, axis=0)\n",
    "# save labels added by yz\n",
    "#np.save(\"labels_pred.npy\", labels_pred)\n",
    "\n",
    "try:\n",
    "    acc = calculate_acc(labels_pred, labels_gt)\n",
    "except:\n",
    "    acc = -1\n",
    "\n",
    "nmi = calculate_nmi(labels_pred, labels_gt)\n",
    "ari = calculate_ari(labels_pred, labels_gt)\n",
    "\n",
    "print(f\"Test Accuracy: {acc}, NMI: {nmi}, ARI: {ari}\")\n",
    "\n",
    "# if args.scores_path is not None:\n",
    "#     np.save(args.scores_path, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m image, target \u001b[39min\u001b[39;00m my_data_loader:\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(image\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m     \u001b[39mprint\u001b[39m(target\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "for image, target in my_data_loader:\n",
    "    print(image.shape)\n",
    "    print(target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hungarian_match(flat_preds, flat_targets):\n",
    "    # Based on implementation from IIC\n",
    "    num_samples = flat_targets.shape[0]\n",
    "    v, counts = np.unique(flat_preds, return_counts=True)\n",
    "\n",
    "    num_k = len(v)\n",
    "    num_correct = np.zeros((num_k, num_k))\n",
    "\n",
    "    for c1 in range(num_k):\n",
    "        for c2 in range(num_k):\n",
    "            # elementwise, so each sample contributes once\n",
    "            votes = int(((flat_preds == c1) * (flat_targets == c2)).sum())\n",
    "            num_correct[c1, c2] = votes\n",
    "\n",
    "    row, col = linear_sum_assignment(num_samples - num_correct)\n",
    "    return row, col\n",
    "\n",
    "\n",
    "def get_prime_Y(noisy_classes, pred_classes, mappings):\n",
    "    prime_Y = np.zeros(len(noisy_classes))\n",
    "    for i in range(len(pred_classes)):\n",
    "        prime_Y[i] = mappings[pred_classes[i]]\n",
    "\n",
    "    return prime_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_dataset.dataset.targets)\n",
    "len (val_dataset.dataset.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({True: 44946, False: 5054})"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2 = _hungarian_match(labels_pred, train_dataset.dataset.targets)\n",
    "prime_Y = get_prime_Y(train_dataset.dataset.targets, labels_pred, idx2[1])\n",
    "\n",
    "#train_loader.dataset.dataset.targets[0]\n",
    "prime_Y\n",
    "\n",
    "import collections\n",
    "res = collections.Counter(prime_Y==train_dataset.dataset.targets)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "410387e4bb6056df1e8fba72755cd1379fbde9775ae114a23afab7a71b2c10e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
